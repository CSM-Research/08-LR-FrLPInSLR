@article{ASSYNE2022111183,
title = {The state of research on software engineering competencies: A systematic mapping study},
journal = {Journal of Systems and Software},
volume = {185},
pages = {111183},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111183},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002648},
author = {Nana Assyne and Hadi Ghanbari and Mirja Pulkkinen},
keywords = {Software engineering, Software development, Competence, Competencies, Essential competencies, Mapping study, Systematic Literature Review},
abstract = {Considering the critical role of software in modern societies, we face an urgent need to educate more competent software professionals. Software engineering competencies (SEC) are considered the backbone of successfully developing software products. Consequently, SEC has become a hotspot for software engineering research and practice. Although scientific literature on SEC is not lacking, to our knowledge, a comprehensive overview of the current state of SEC research is missing. To that end, we conducted an extensive and systematic review of the SEC literature. We provide an overview of the current state of research on SEC, with a particular focus on common SEC research areas. In addition to reporting the available SEC models and frameworks, we compile a list of 49 unique essential competencies of software professionals. Finally, we highlight several gaps in the literature that deserve further research. In particular, we call for a better understanding of how the essential competencies of software professionals change over time, as well as fresh accounts of the essential competencies of software professionals. Additionally, considering recent shifts toward Agile and DevOps methods, future research must explore the competencies required for developing software products in modern development environments.}
}
@article{CAPILLA2021106439,
title = {Software engineering and advanced applications conference 2019 – selected papers},
journal = {Information and Software Technology},
volume = {130},
pages = {106439},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106439},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920301920},
author = {Rafael Capilla and Miroslaw Staron},
abstract = {Software Engineering and Advanced Applications (SEAA) is a long-standing international forum for researchers, practitioners, and students to present and discuss the latest innovations, trends, experiences, and concerns in the field of Software Engineering and Advanced Applications in information technology for software-intensive systems. In this special issue, we present a selection of papers which show the current trends in software engineering – improved systematic reviews, deep learning and cloud computing.}
}
@article{AZZEH2021102596,
title = {Predicting software effort from use case points: A systematic review},
journal = {Science of Computer Programming},
volume = {204},
pages = {102596},
year = {2021},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2020.102596},
url = {https://www.sciencedirect.com/science/article/pii/S0167642320302045},
author = {Mohammad Azzeh and Ali {Bou Nassif} and Imtinan Basem Attili},
keywords = {Systematic literature review, Use case points, Effort estimation},
abstract = {Context: Predicting software project effort from Use Case Points (UCP) method is increasingly used among researchers and practitioners. However, unlike other effort estimation domains, this area of interest has not been systematically reviewed. Aims: There is a need for a systemic literature review to provide directions and supports for this research area of effort estimation. Specifically, the objective of this study is twofold: 1) to classify UCP effort estimation papers based on four criteria: contribution type, research approach, dataset type and techniques used with UCP; and 2) to analyze these paper from different views: estimation accuracy, favorable estimation context and impact of combined techniques on the accuracy of UCP. Method: We used the systematic literature review methodology proposed by Kitchenham and Charters. This includes searching for the most relevant papers, selecting quality papers, extracting data and drawing results. Result: The authors of UCP research paper, are generally not aware of previous published results and conclusions in the field of UCP effort estimation. There is a lack of UCP related publications in the top software engineering journals. This makes a conclusion that such papers are not useful for the community. Furthermore, most articles used small numbers of projects which cannot support generalizing the conclusion in most cases. Conclusions: There are multiple research directions for UCP method that have not been examined so far such as validating the algebraic construction of UCP based on industrial data. Also, there is a need for standard automated tools that govern the process of translating use case diagram into its corresponding UCP metrics. Although there is an increase interest among researchers to collect industrial data and build effort prediction models based on machine learning methods, the quality of data is still subject to debate.}
}
@article{LENARDUZZI2021110827,
title = {A systematic literature review on Technical Debt prioritization: Strategies, processes, factors, and tools},
journal = {Journal of Systems and Software},
volume = {171},
pages = {110827},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110827},
url = {https://www.sciencedirect.com/science/article/pii/S016412122030220X},
author = {Valentina Lenarduzzi and Terese Besker and Davide Taibi and Antonio Martini and Francesca {Arcelli Fontana}},
keywords = {Technical Debt, Technical Debt prioritization, Systematic Literature Review},
abstract = {Background
Software companies need to manage and refactor Technical Debt issues. Therefore, it is necessary to understand if and when refactoring of Technical Debt should be prioritized with respect to developing features or fixing bugs.
Objective
The goal of this study is to investigate the existing body of knowledge in software engineering to understand what Technical Debt prioritization approaches have been proposed in research and industry.
Method
We conducted a Systematic Literature Review of 557 unique papers published until 2020, following a consolidated methodology applied in software engineering. We included 44 primary studies.
Results
Different approaches have been proposed for Technical Debt prioritization, all having different goals and proposing optimization regarding different criteria. The proposed measures capture only a small part of the plethora of factors used to prioritize Technical Debt qualitatively in practice. We present an impact map of such factors. However, there is a lack of empirical and validated set of tools.
Conclusion
We observed that Technical Debt prioritization research is preliminary and there is no consensus on what the important factors are and how to measure them. Consequently, we cannot consider current research conclusive. In this paper, we therefore outline different directions for necessary future investigations.}
}
@article{WIMALASOORIYA2022111166,
title = {A systematic mapping study addressing the reliability of mobile applications: The need to move beyond testing reliability},
journal = {Journal of Systems and Software},
volume = {186},
pages = {111166},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111166},
url = {https://www.sciencedirect.com/science/article/pii/S016412122100251X},
author = {Chathrie Wimalasooriya and Sherlock A. Licorish and Daniel Alencar da Costa and Stephen G. MacDonell},
keywords = {Mapping study, Software reliability, Mobile app reliability, Evidence-based software engineering},
abstract = {Intense competition in the mobile apps market means it is important to maintain high levels of app reliability to avoid losing users. Yet despite its importance, app reliability is underexplored in the research literature. To address this need, we identify, analyse, and classify the state-of-the-art in the field of mobile apps’ reliability through a systematic mapping study. From the results of such a study, researchers in the field can identify pressing research gaps, and developers can gain knowledge about existing solutions, to potentially leverage them in practice. We found 87 relevant papers which were then analysed and classified based on their research focus, research type, contribution, research method, study settings, data, quality attributes and metrics used. Results indicate that there is a lack of research on understanding reliability with regard to context-awareness, self-healing, ageing and rejuvenation, and runtime event handling. These aspects have rarely been studied, or if studied, there is limited evaluation. We also identified several other research gaps including the need to conduct more research in real-world industrial projects. Furthermore, little attention has been paid towards quality standards while conducting research. Outcomes here show numerous opportunities for greater research depth and breadth on mobile app reliability.}
}
@article{KAMEI2021106609,
title = {Grey Literature in Software Engineering: A critical review},
journal = {Information and Software Technology},
volume = {138},
pages = {106609},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106609},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921000860},
author = {Fernando Kamei and Igor Wiese and Crescencio Lima and Ivanilton Polato and Vilmar Nepomuceno and Waldemar Ferreira and Márcio Ribeiro and Carolline Pena and Bruno Cartaxo and Gustavo Pinto and Sérgio Soares},
keywords = {Grey Literature, Tertiary study, Secondary Study, Software Engineering, Multivocal Literature Review, Grey Literature Review, Systematic Literature Review, Mapping Study},
abstract = {Context:
Grey Literature (GL) recently has grown in Software Engineering (SE) research since the increased use of online communication channels by software engineers. However, there is still a limited understanding of how SE research is taking advantage of GL.
Objective:
This research aimed to understand how SE researchers use GL in their secondary studies.
Methods:
We conducted a tertiary study of studies published between 2011 and 2018 in high-quality software engineering conferences and journals. We then applied qualitative and quantitative analysis to investigate 446 potential studies.
Results:
From the 446 selected studies, 126 studies cited GL but only 95 of those used GL to answer a specific research question representing almost 21% of all the 446 secondary studies. Interestingly, we identified that few studies employed specific search mechanisms and used additional criteria for assessing GL. Moreover, by the time we conducted this research, 49% of the GL URLs are not working anymore. Based on our findings, we discuss some challenges in using GL and potential mitigation plans.
Conclusion:
In this paper, we summarized the last 10 years of software engineering research that uses GL, showing that GL has been essential for bringing practical new perspectives that are scarce in traditional literature. By drawing the current landscape of use, we also raise some awareness of related challenges (and strategies to deal with them).}
}
@article{ASSYNE2022107020,
title = {The essential competencies of software professionals: A unified competence framework},
journal = {Information and Software Technology},
volume = {151},
pages = {107020},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.107020},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922001446},
author = {Nana Assyne and Hadi Ghanbari and Mirja Pulkkinen},
keywords = {Software engineering, Software development, Competence, Competencies, Kano model},
abstract = {Context
Developing high-quality software requires skilled software professionals equipped with a set of basic and essential software engineering competencies (SEC). These competencies and the satisfaction levels derived from them change over a project's lifecycle, or as software professionals move from one project to another.
Objective
Previous studies suggest a lack of means enabling SEC stakeholders to identify and assess competencies suitable for different projects. Additionally, previous research has mainly portrayed SEC to be static and overlooked their evolution over time and across projects. We investigate how we could effectively identify and match the competencies of software professionals necessary for different projects.
Method
We follow a mixed-method approach to iteratively develop and evaluate a framework for identifying and managing SEC. In so doing, we use the results of an extensive literature review, focus group discussions with experts from academia and industry, and data collected through interviews with 138 individuals with a supervisory role in the software industry.
Results
Drawing on the Kano model and Competency Framework for Software Engineers, we propose a Unified Competence Gate for Software Professionals (UComGSP), a framework for identifying and managing SEC. The UComGSP consists of 62 hard competencies, 63 soft competencies, and 25 essential SEC competencies. Additionally, we propose three stakeholders’ satisfaction levels for SEC assessment: basic, performance, and delighter. Furthermore, based on empirical observation, we report 27 competencies not mentioned in the reviewed literature; 11 of them are considered essential competencies.
Conclusion
Competence development involves different stakeholders, including software professionals, educators, and the software industry. The UComGSP framework enables SEC stakeholders to (i) identify SE competencies, (ii) identify the essential SEC, and (iii) assess the satisfaction levels that can be derived from different competencies. Future research is needed to evaluate the effectiveness of the proposed framework across software development projects.}
}
@article{VACCA2021110891,
title = {A systematic literature review of blockchain and smart contract development: Techniques, tools, and open challenges},
journal = {Journal of Systems and Software},
volume = {174},
pages = {110891},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110891},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302818},
author = {Anna Vacca and Andrea {Di Sorbo} and Corrado A. Visaggio and Gerardo Canfora},
keywords = {Software engineering for blockchain technologies, Software quality, Software metrics, Empirical study, Ethereum, Smart contract},
abstract = {Blockchain platforms and languages for writing smart contracts are becoming increasingly popular. However, smart contracts and blockchain applications are developed through non-standard software life-cycles, in which, for instance, delivered applications can hardly be updated or bugs resolved by releasing a new version of the software. Therefore, this systematic literature review oriented to software engineering aims at highlighting current problems and possible solutions concerning smart contracts and blockchain applications development. In this paper, we analyze 96 articles (written from 2016 to 2020) presenting solutions to tackle software engineering-specific challenges related to the development, test, and security assessment of blockchain-oriented software. In particular, we review papers (that appeared in international journals and conferences) relating to six specific topics: smart contract testing, smart contract code analysis, smart contract metrics, smart contract security, Dapp performance, and blockchain applications. Beyond the systematic review of the techniques, tools, and approaches that have been proposed in the literature to address the issues posed by the development of blockchain-based software, for each of the six aforementioned topics, we identify open challenges that require further research.}
}
@article{DEY2021110941,
title = {Multilayered review of safety approaches for machine learning-based systems in the days of AI},
journal = {Journal of Systems and Software},
volume = {176},
pages = {110941},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110941},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000388},
author = {Sangeeta Dey and Seok-Won Lee},
keywords = {Autonomous systems, Intelligent software systems, Machine learning, Safety analysis, Software engineering},
abstract = {The unprecedented advancement of artificial intelligence (AI) in recent years has altered our perspectives on software engineering and systems engineering as a whole. Nowadays, software-intensive intelligent systems rely more on a learning model than thousands of lines of codes. Such alteration has led to new research challenges in the engineering process that can ensure the safe and beneficial behavior of AI systems. This paper presents a literature survey of the significant efforts made in the last fifteen years to foster safety in complex intelligent systems. This survey covers relevant aspects of AI safety research including safety requirements engineering, safety-driven design at both system and machine learning (ML) component level, validation and verification from the perspective of software and system engineers. We categorize these research efforts based on a three-layered conceptual framework for developing and maintaining AI systems. We also perform a gap analysis to emphasize the open research challenges in ensuring safe AI. Finally, we conclude the paper by providing future research directions and a road map for AI safety.}
}
@article{VANDINTER2022107008,
title = {Predictive maintenance using digital twins: A systematic literature review},
journal = {Information and Software Technology},
volume = {151},
pages = {107008},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.107008},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922001331},
author = {Raymon {van Dinter} and Bedir Tekinerdogan and Cagatay Catal},
keywords = {Systematic literature review, Active learning, Digital twin, Predictive maintenance},
abstract = {Context
Predictive maintenance is a technique for creating a more sustainable, safe, and profitable industry. One of the key challenges for creating predictive maintenance systems is the lack of failure data, as the machine is frequently repaired before failure. Digital Twins provide a real-time representation of the physical machine and generate data, such as asset degradation, which the predictive maintenance algorithm can use. Since 2018, scientific literature on the utilization of Digital Twins for predictive maintenance has accelerated, indicating the need for a thorough review.
Objective
This research aims to gather and synthesize the studies that focus on predictive maintenance using Digital Twins to pave the way for further research.
Method
A systematic literature review (SLR) using an active learning tool is conducted on published primary studies on predictive maintenance using Digital Twins, in which 42 primary studies have been analyzed.
Results
This SLR identifies several aspects of predictive maintenance using Digital Twins, including the objectives, application domains, Digital Twin platforms, Digital Twin representation types, approaches, abstraction levels, design patterns, communication protocols, twinning parameters, and challenges and solution directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry.
Conclusion
This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models.}
}
@article{PEISCHL2022111387,
title = {Testing anticipatory systems: A systematic mapping study on the state of the art},
journal = {Journal of Systems and Software},
volume = {192},
pages = {111387},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111387},
url = {https://www.sciencedirect.com/science/article/pii/S016412122200108X},
author = {Bernhard Peischl and Oliver A. Tazl and Franz Wotawa},
keywords = {Anticipatory systems, Artificial intelligence, Software testing, Mapping study, Verification, Validation},
abstract = {Context:
Systems exhibiting anticipatory behavior are controlling devices that are influencing decisions critical to business with increasing frequency, but testing such systems has received little attention from the artificial intelligence or software engineering communities.
Goal:
In this article, we describe research activities being carried out to test anticipatory systems and explore how this research contributes to the body of knowledge. In addition, we review the types of addressed anticipatory applications and point out open issues and trends.
Method:
This systematic mapping study was conducted to classify and analyze the literature on testing anticipatory systems, enabling us to highlight the most relevant topics and potential gaps in this field.
Results:
We identified 206 studies that contribute to the testing of systems that exhibit anticipatory behavior. The papers address testing at stages such as context sensing, inferring higher-level concepts from the sensed data, predicting the future context, and intelligent decision-making. We also identified agent testing as a trend, among others.
Conclusion:
The existing literature on testing anticipatory systems has originated from various research communities, such as those on autonomous agents and quality engineering. Although researchers have recently exhibited increasing interest in testing anticipatory systems, theoretical knowledge about testing such systems is lacking.}
}
@article{FARINA2022100187,
title = {Interest identification from browser tab titles: A systematic literature review},
journal = {Computers in Human Behavior Reports},
volume = {7},
pages = {100187},
year = {2022},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2022.100187},
url = {https://www.sciencedirect.com/science/article/pii/S2451958822000215},
author = {Mirko Farina and Maxim Kostin and Giancarlo Succi},
keywords = {Software engineering, User interests identification, Non-verbal communication, Empirical studies, Systematic literature review},
abstract = {Modeling and understanding users interests has become an essential part of our daily lives. A variety of business processes and a growing number of companies employ various tools to such an end. The outcomes of these identification strategies are beneficial for both companies and users: the former are more likely to offer services to those customers who really need them, while the latter are more likely to get the service they desire. Several works have been carried out in the area of user interests identification. As a result, it might not be easy for researchers, developers, and users to orient themselves in the field; that is, to find the tools and methods that they most need, to identify ripe areas for further investigations, and to propose the development and adoption of new research plans. In this study, to overcome these potential shortcomings, we performed a systematic literature review on user interests identification. We used as input data browsing tab titles. Our goal here is to offer a service to the readership, which is capable of systematically guiding and reliably orienting researchers, developers, and users in this very vast domain. Our findings demonstrate that the majority of the research carried out in the field gathers data from either social networks (such as Twitter, Instagram and Facebook) or from search engines, leaving open the question of what to do when such data is not available.}
}
@article{GIORDANO2022111475,
title = {On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {193},
pages = {111475},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111475},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001613},
author = {Giammaria Giordano and Fabio Palomba and Filomena Ferrucci},
keywords = {Data privacy, Artificial intelligence, Internet-of-Things, Software engineering for IoT},
abstract = {The Internet of Things (IoT) refers to a network of Internet-enabled devices that can make different operations, like sensing, communicating, and reacting to changes arising in the surrounding environment. Nowadays, the number of IoT devices is already higher than the world population. These devices operate by exchanging data between them, sometimes through an intermediate cloud infrastructure, and may be used to enable a wide variety of novel services that can potentially improve the quality of life of billions of people. Nonetheless, all that glitters is not gold: the increasing adoption of IoT comes with several privacy concerns due to the lack or loss of control over the sensitive data exchanged by these devices. This represents a key challenge for software engineering researchers attempting to address those privacy concerns by proposing (semi-)automated solutions to identify sources of privacy leaks. In this respect, a notable trend is represented by the adoption of smart solutions, that is, the definition of techniques based on artificial intelligence (AI) algorithms. This paper proposes a systematic literature review of the research in smart detection of privacy concerns in IoT devices. Following well-established guidelines, we identify 152 primary studies that we analyze under three main perspectives: (1) What are the privacy concerns addressed with AI-enabled techniques; (2) What are the algorithms employed and how they have been configured/validated; and (3) Which are the domains targeted by these techniques. The key results of the study identified six main tasks targeted through the use of artificial intelligence, like Malware Detection or Network Analysis. Support Vector Machine is the technique most frequently used in literature, however in many cases researchers do not explicitly indicate the domain where to use artificial intelligence algorithms. We conclude the paper by distilling several lessons learned and implications for software engineering researchers.}
}
@article{YANG2021106397,
title = {Quality Assessment in Systematic Literature Reviews: A Software Engineering Perspective},
journal = {Information and Software Technology},
volume = {130},
pages = {106397},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106397},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920301610},
author = {Lanxin Yang and He Zhang and Haifeng Shen and Xin Huang and Xin Zhou and Guoping Rong and Dong Shao},
keywords = {Quality assessment, Systematic (literature) review, Tertiary study, Empirical software engineering, Evidence-based software engineering},
abstract = {Context: Quality Assessment (QA) of reviewed literature is paramount to a Systematic Literature Review (SLR) as the quality of conclusions completely depends on the quality of selected literature. A number of researchers in Software Engineering (SE) have developed a variety of QA instruments and also reported their challenges. We previously conducted a tertiary study on SLRs with QA from 2004 to 2013, and reported the findings in 2015. Objective: With the widespread use of SLRs in SE and the increasing adoption of QA in these SLRs in recent years, it is necessary to empirically investigate whether the previous conclusions are still valid and whether there are new insights to the subject in question using a larger and a more up-to-date SLR set. More importantly, we aim to depict a clear picture of QA used in SLRs in SE by aggregating and distilling good practices, including the commonly used QA instruments as well as the major roles and aspects of QA in research. Method: An extended tertiary study was conducted with the newly collected SLRs from 2014 to 2018 and the original SLRs from 2004 to 2013 to systematically review the QA used by SLRs in SE during the 15-year period from 2004 to 2018. In addition, this extended study also compared and contrasted the findings of the previous study conducted in 2015. Results: A total of 241 SLRs between 2004 and 2018 were included, from which we identified a number of QA instruments. These instruments are generally designed to focus on the rationality of study design, the rigor of study execution and analysis, and the credibility and contribution of study findings and conclusions, with the emphasis largely placed on its rigor. The quality data is mainly used for literature selection or as evidence to support conclusions. Conclusions: QA has received much attention in SE in more recent years and the improvement is evident since the last study in 2015. New findings show that the aims are more concise, the instruments are more diverse and rigorous, and the criteria are more thoughtful.}
}
@article{PINCIROLI20222883,
title = {Systematic mapping study: On the coverage of aspect-oriented methodologies for the early phases of the software development life cycle},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {6, Part A},
pages = {2883-2896},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2020.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S1319157820305231},
author = {Fernando Pinciroli and Jose Luis {Barros Justo} and Raymundo Forradellas},
keywords = {Systematic mapping study, Systematic review, Evidence-based software engineering, Aspect-oriented system development, Aspect-oriented tools, notations and techniques, Aspect-oriented paradigm benefits, Aspect-oriented paradigm challenges},
abstract = {Although the number of aspect-oriented software development techniques and tools proposed by the scientific literature have been increasing since the late 80′s, the evidence about the benefits that the aspect-oriented paradigm have reached in real-world settings is scarce. Our objective is to identify and classify the aspect-oriented software development methodologies used to reduce the effort and costs of moving from traditional approaches to the aspect-oriented approach in real-world settings. We conducted a systematic mapping study (SMS). Our search strategies retrieved a set of 3212 papers out of which 115 were selected as relevant studies. We defined eight categories to classify these studies: aspect-oriented methodologies proposed for early aspects; development early phases covered; notations; modeling techniques; supporting tools; aspect-oriented methodologies used in real-world settings; benefits reported and unsolved issues. As a result, 39 named methodologies were reported; they cover the business modeling (14 papers), requirements (93 papers), test cases (1 paper) and design (41 papers) phases of the software development life cycle (SDLC); we found 36 different notations, with UML as the most mentioned (66 papers); 22 modeling techniques were found, where the use cases were the ones that appeared the most, on 43 occasions; 43 support tools of which none was repeated in more than 3 articles; 15 applications in real-world settings; 17 benefits, modularization being the most mentioned with 4 occurrences; and 15 pending improvement opportunities. Finally, we have obtained conclusions: the literature analyzed demonstrates that there are no prevailing standards on methodologies and notations, beyond that the most employed are those belonging to the OMG; we have not found any methodology that includes all phases of the SDLC; the diagrams corresponding to OMG’s standards account for 78% of the results in the facet of modeling techniques; there are no tools that have the greatest predilection and the most used is mentioned only three times; in addition, 41% of the articles do not mention any tool; the evidence of aspect-oriented methodologies application in real-world settings reached just the 10%, although the declared benefits are coincident with those promised in the aspect-orientated literature. The mentioned pending issues can guide new studies (RQ8).}
}
@article{YU2022116958,
title = {Assessing expert system-assisted literature reviews with a case study},
journal = {Expert Systems with Applications},
volume = {200},
pages = {116958},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116958},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422003852},
author = {Zhe Yu and Jeffrey C. Carver and Gregg Rothermel and Tim Menzies},
keywords = {Systematic literature review, Expert systems, Software engineering, Active learning, Primary study selection, Test case prioritization},
abstract = {Given the large numbers of publications in software engineering, frequent literature reviews are required to keep current on work in specific areas. One tedious work in literature reviews is to find relevant studies amongst thousands of non-relevant search results. In theory, expert systems can assist in finding relevant work but those systems have primarily been tested in simulations rather than in application to actual literature reviews. Hence, few researchers have faith in such expert systems. Accordingly, using a realistic case study, this paper assesses how well our state-of-the-art expert system can help with literature reviews. The assessed literature review aimed at identifying test case prioritization techniques for automated UI testing, specifically from 8,349 papers on IEEE Xplore. This corpus was studied with an expert system that incorporates an incrementally updated human-in-the-loop active learning tool. Using that expert system, in three hours, we found 242 relevant papers from which we identified 12 techniques representing the state-of-the-art in test case prioritization when source code information is not available. These results were then validated by six other graduate students manually exploring the same corpus. Without the expert system, this task would have required 53 h and would have found 27 additional papers. That is, our expert system achieved 90% recall with 6% of the human effort cost when compared to a conventional manual method. Significantly, the same 12 state-of-the-art test case prioritization techniques were identified by both the expert system and the manual method. That is, the 27 papers missed by the expert system would not have changed the conclusion of the literature review. Hence, if this result generalizes, it endorses the use of our expert system to assist in literature reviews.}
}
@incollection{ROZANC2021115,
title = {Chapter Three - The screening phase in systematic reviews: Can we speed up the process?},
editor = {Ali R. Hurson},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {123},
pages = {115-191},
year = {2021},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000310},
author = {Igor Rožanc and Marjan Mernik},
keywords = {Software engineering, Systematic review, Systematic literature review, Systematic mapping study, Article screening, Automatic screening process, Tool},
abstract = {The aim of a systematic reviews (SRs) is to gain a better understanding of a certain aspect of selected research field using the principle of classification of a large number of carefully selected articles. Selection of a proper set of articles is a crucial yet delicate task, which demands a large portion of tedious manual work. This article proposes to automate the screening of a large set of articles while conducting an SR. A rigorous approach is described, which conforms with the SR guidelines, and a tool to efficiently support such an approach is presented as well. The effect of approach is presented by a demonstration experiment which compares its results with the results of a classic manual screening. Finally, the recommendations for the proper use of the approach (i.e., the size of the pilot set and decision rule structure) are presented.}
}
@article{PAVLIC2022104470,
title = {Towards a novel catalog of assessment patterns for distant education in the information technology domain},
journal = {Computers & Education},
volume = {182},
pages = {104470},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104470},
url = {https://www.sciencedirect.com/science/article/pii/S0360131522000410},
author = {Luka Pavlič and Tina Beranič and Lucija Brezočnik and Marjan Heričko},
keywords = {Distance education and online learning, Improving classroom teaching, Pedagogical issues, Teacher professional development, Post-secondary educations},
abstract = {This paper presents a research and its results in the domain of higher education's pedagogical patterns for remote assessments - precisely in the computer science, software engineering and informatics-related courses. This research was motivated by the COVID-19 crisis, which separated teachers, teaching assistants, and students physically. During this period, remote knowledge assessment was one of the most challenging among all educational activities. The lack of available resources and advice on remote knowledge assessment revealed a need for a specialized assessment pattern catalog. The main result of the research is the assessment pattern catalog that started to grow organically at the Institute of Informatics, where we teach IT-related courses. We started with the initial set of patterns, identified by analyzing recurring practices, applied by teaching staff for remote assessments in the period from March 2020 till December 2020. The patterns were aggregated and gradually refined using a systematic approach. In addition to guided workshops, a systematic literature review was employed, followed by catalog refinements, and, finally, an extensive survey was carried out among teachers and teaching assistants. The latter was used as a validation of the correctness of the novel assessment pattern catalog, as well as the presented patterns’ suitability and popularity among users. The resulting assessment pattern catalog presented in this paper boasts 47 patterns, classified into four main categories, that support the whole process of (remote) assessment. It is organized and documented systematically. It also boasts several indicators per each pattern to demonstrate its suitability for distant assessments, popularity rankings among teachers, teaching assistants, and top picks in every category per teachers and teaching assistants. The survey that we performed revealed a subset of patterns that are important for a successful remote assessment, validated in the IT-related courses. Based on the results, the presented assessment pattern catalog showed itself to be useful not only for the remote assessment but also for judging knowledge in the classroom successfully.}
}
@article{RAJAPAKSE2022106700,
title = {Challenges and solutions when adopting DevSecOps: A systematic review},
journal = {Information and Software Technology},
volume = {141},
pages = {106700},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106700},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921001543},
author = {Roshan N. Rajapakse and Mansooreh Zahedi and M. Ali Babar and Haifeng Shen},
keywords = {DevOps, Security, DevSecOps, Continuous Software Engineering, Systematic Literature Review},
abstract = {Context:
DevOps (Development and Operations) has become one of the fastest-growing software development paradigms in the industry. However, this trend has presented the challenge of ensuring secure software delivery while maintaining the agility of DevOps. The efforts to integrate security in DevOps have resulted in the DevSecOps paradigm, which is gaining significant interest from both industry and academia. However, the adoption of DevSecOps in practice is proving to be a challenge.
Objective:
This study aims to systemize the knowledge about the challenges faced by practitioners when adopting DevSecOps and the proposed solutions reported in the literature. We also aim to identify the areas that need further research in the future.
Method:
We conducted a Systematic Literature Review of 54 peer-reviewed studies. The thematic analysis method was applied to analyze the extracted data.
Results:
We identified 21 challenges related to adopting DevSecOps, 31 specific solutions, and the mapping between these findings. We also determined key gap areas in this domain by holistically evaluating the available solutions against the challenges. The results of the study were classified into four themes: People, Practices, Tools, and Infrastructure. Our findings demonstrate that tool-related challenges and solutions were the most frequently reported, driven by the need for automation in this paradigm. Shift-left security and continuous security assessment were two key practices recommended for DevSecOps. People-related factors were considered critical for successful DevSecOps adoption but less studied.
Conclusions:
We highlight the need for developer-centered application security testing tools that target the continuous practices in DevSecOps. More research is needed on how the traditionally manual security practices can be automated to suit rapid software deployment cycles. Finally, achieving a suitable balance between the speed of delivery and security is a significant issue practitioners face in the DevSecOps paradigm.}
}
@article{SHAIKH2021e06629,
title = {How to form a software engineering capstone team?},
journal = {Heliyon},
volume = {7},
number = {4},
pages = {e06629},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e06629},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021007325},
author = {Muhammad Khalid Shaikh},
keywords = {Engineering education, Team formation, Capstone project, Software engineering, Cohesion, Psychographics},
abstract = {This research paper answers the question that how shall the students of software engineering undergraduate courses form teams for the capstone projects that can be cohesive too. In this research, 128 criteria for team formation are proposed for building teams for self-managing software engineering capstone projects. A comparison is also conducted to ascertain the level of cohesion among those teams that were formed using the proposed criteria and those that were not formed using the proposed criteria. The criteria were identified through a combination of qualitative questionnaire survey targeted at the graduated students of the past batches of Computer Science degree program and through synthesizing the literature on engineering capstone project teams identified under the guidance of KSAO framework for software engineering students. To check the effectiveness of the criteria, 100 students were asked to form the teams using the proposed criteria and other 100 students formed the teams without the proposed criteria. Those students that had used the proposed criteria for building teams and those that had formed teams without using the proposed criteria were asked to fill the modified Group Environment Questionnaire to ascertain the level of cohesion among the team members. The results were analyzed qualitatively and through descriptive quantification. The results show that the level of cohesion in teams that were formed using the proposed team building criteria was higher. There was a need for team building criteria in the literature on software engineering capstone project teams that conforms to a conceptual, theoretical framework; this gap is now filled through this research. This paper may also serve as a literature review paper for some readers.}
}
@article{VIDONI2022106791,
title = {A systematic process for Mining Software Repositories: Results from a systematic literature review},
journal = {Information and Software Technology},
volume = {144},
pages = {106791},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106791},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921002317},
author = {M. Vidoni},
keywords = {Mining Software Repositories, Systematic literature review, Evidence-based software engineering, Guidelines},
abstract = {Context:
Mining Software Repositories (MSR) is a growing area of Software Engineering (SE) research. Since their emergence in 2004, many investigations have analysed different aspects of these studies. However, there are no guidelines on how to conduct systematic MSR studies. There is a need to evaluate how MSR research is approached to provide a framework to do so systematically.
Objective:
To identify how MSR studies are conducted in terms of repository selection and data extraction. To uncover potential for improvement in directing systematic research and providing guidelines to do so.
Method:
A systematic literature review of MSR studies was conducted following the guidelines and template proposed by Mian et al. (which refines those provided by Kitchenham and Charters). These guidelines were extended and revised to provide a framework for systematic MSR studies.
Results:
MSR studies typically do not follow a systematic approach for repository selection, and many do not report selection or data extraction protocols. Furthermore, few manuscripts discuss threats to the study’s validity due to the selection or data extraction steps followed.
Conclusions:
Although MSR studies are evidence-based research, they seldom follow a systematic process. Hence, there is a need for guidelines on how to conduct systematic MSR studies. New guidelines and a template have been proposed, consolidating related studies in the MSR field and strategies for systematic literature reviews.}
}
@article{WEBER2021110946,
title = {Brain and autonomic nervous system activity measurement in software engineering: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {178},
pages = {110946},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110946},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000431},
author = {Barbara Weber and Thomas Fischer and René Riedl},
keywords = {Brain and autonomic nervous system activity measurements, Software engineering, Systematic literature review, Electroencephalography (EEG), Functional magnetic resonance imaging (fMRI), Heart- and skin-related measurements},
abstract = {In the past decade, brain and autonomic nervous system activity measurement received increasing attention in the study of software engineering (SE). This paper presents a systematic literature review (SLR) to survey the existing NeuroSE literature. Based on a rigorous search protocol, we identified 89 papers (hereafter denoted as NeuroSE papers). We analyzed these papers to develop a comprehensive understanding of who had published NeuroSE research and classified the contributions according to their type. The 47 articles presenting completed empirical research were analyzed in detail. The SLR revealed that the number of authors publishing NeuroSE research is still relatively small. The thematic focus so far has been on code comprehension, while code inspection, programming, and bug fixing have been less frequently studied. NeuroSE publications primarily used methods related to brain activity measurement (particularly fMRI and EEG), while methods related to the measurement of autonomic nervous system activity (e.g., pupil dilation, heart rate, skin conductance) received less attention. We also present details of how the empirical research was conducted, including stimuli and independent and dependent variables, and discuss implications for future research. The body of NeuroSE literature is still small. Yet, high quality contributions exist constituting a valuable basis for future studies.}
}
@article{YAO2021106664,
title = {The impact of using biased performance metrics on software defect prediction research},
journal = {Information and Software Technology},
volume = {139},
pages = {106664},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106664},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921001270},
author = {Jingxiu Yao and Martin Shepperd},
keywords = {Software engineering, Machine learning, Software defect prediction, Computational experiment, Classification metrics},
abstract = {Context:
Software engineering researchers have undertaken many experiments investigating the potential of software defect prediction algorithms. Unfortunately some widely used performance metrics are known to be problematic, most notably F1, but nevertheless F1 is widely used.
Objective:
To investigate the potential impact of using F1 on the validity of this large body of research.
Method:
We undertook a systematic review to locate relevant experiments and then extract all pairwise comparisons of defect prediction performance using F1 and the unbiased Matthews correlation coefficient (MCC).
Results:
We found a total of 38 primary studies. These contain 12,471 pairs of results. Of these comparisons, 21.95% changed direction when the MCC metric is used instead of the biased F1 metric. Unfortunately, we also found evidence suggesting that F1 remains widely used in software defect prediction research.
Conclusion:
We reiterate the concerns of statisticians that the F1 is a problematic metric outside of an information retrieval context, since we are concerned about both classes (defect-prone and not defect-prone units). This inappropriate usage has led to a substantial number (more than one fifth) of erroneous (in terms of direction) results. Therefore we urge researchers to (i) use an unbiased metric and (ii) publish detailed results including confusion matrices such that alternative analyses become possible.}
}
@article{ARVANITOU2021110848,
title = {Software engineering practices for scientific software development: A systematic mapping study},
journal = {Journal of Systems and Software},
volume = {172},
pages = {110848},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110848},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302387},
author = {Elvira-Maria Arvanitou and Apostolos Ampatzoglou and Alexander Chatzigeorgiou and Jeffrey C. Carver},
keywords = {Software engineering practices, High performance computing, Scientific computing},
abstract = {Background:
The development of scientific software applications is far from trivial, due to the constant increase in the necessary complexity of these applications, their increasing size, and their need for intensive maintenance and reuse.
Aim:
To this end, developers of scientific software (who usually lack a formal computer science background) need to use appropriate software engineering (SE) practices. This paper describes the results of a systematic mapping study on the use of SE for scientific application development and their impact on software quality.
Method:
To achieve this goal we have performed a systematic mapping study on 359 papers. We first describe a catalog of SE practices used in scientific software development. Then, we discuss the quality attributes of interest that drive the application of these practices, as well as tentative side-effects of applying the practices on qualities.
Results:
The main findings indicate that scientific software developers are focusing on practices that improve implementation productivity, such as code reuse, use of third-party libraries, and the application of “good” programming techniques. In addition, apart from the finding that performance is a key-driver for many of these applications, scientific software developers also find maintainability and productivity to be important.
Conclusions:
The results of the study are compared to existing literature, are interpreted under a software engineering prism, and various implications for researchers and practitioners are provided. One of the key findings of the study, which is considered as important for driving future research endeavors is the lack of evidence on the trade-offs that need to be made when applying a software practice, i.e., negative (indirect) effects on other quality attributes.}
}
@article{JIA2021106478,
title = {A systematic review of scheduling approaches on multi-tenancy cloud platforms},
journal = {Information and Software Technology},
volume = {132},
pages = {106478},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106478},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920302214},
author = {Ru Jia and Yun Yang and John Grundy and Jacky Keung and Li Hao},
keywords = {Systematic review, Survey, Cloud computing, Multi-tenancy, Scheduling},
abstract = {Context:
Scheduling in cloud is complicated as a result of multi-tenancy. Diverse tenants have different requirements, including service functions, response time, QoS and throughput. Diverse tenants require different scheduling capabilities, resource consumption and competition. Multi-tenancy scheduling approaches have been developed for different service models, such as Software as a Service (SaaS), Platform as a service (PaaS), Infrastructure as a Service (IaaS), and Database as a Service (DBaaS).
Objective:
In this paper, we survey the current landscape of multi-tenancy scheduling, laying out the challenges and complexity of software engineering where multi-tenancy issues are involved. This study emphasises scheduling policies, cloud provisioning and deployment with regards to multi-tenancy issues. We conduct a systematic literature review of research studies related to multi-tenancy scheduling approaches on cloud platforms determine the primary scheduling approaches currently used and the challenges for addressing key multi-tenancy scheduling issues.
Method:
We adopted a systematic literature review method to search and review many major journal and conference papers on four major online electronic databases, which address our four predefined research questions. Defining inclusion and exclusion criteria was the initial step before extracting data from the selected papers and deriving answers addressing our enquiries.
Results:
Finally, 53 papers were selected, of which 62 approaches were identified. Most of these methods are developed without cloud layers’ limitation (43.40%) and on SaaS, most of scheduling approaches are oriented to framework design (43.75%).
Conclusion:
The results have demonstrated most of multi-tenancy scheduling solutions can work at any delivery layer. With the difference of tenants’ requirements and functionalities, the choice of cloud service delivery models is changed. Based on our study, designing a multi-tenancy scheduling framework should consider the following 3 factors: computing, QoS and storage resource. One of the potential research foci of multi-tenancy scheduling approaches is on GPU scheduling.}
}
@article{ZHANG2021106607,
title = {Processes, challenges and recommendations of Gray Literature Review: An experience report},
journal = {Information and Software Technology},
volume = {137},
pages = {106607},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106607},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921000847},
author = {He Zhang and Runfeng Mao and Huang Huang and Qiming Dai and Xin Zhou and Haifeng Shen and Guoping Rong},
keywords = {Gray literature review, Evidence-based software engineering, DevSecOps},
abstract = {Context:
Systematic Literature Review (SLR), as a tool of Evidence-Based Software Engineering (EBSE), has been widely used in Software Engineering (SE). However, for certain topics in SE, especially those that are trendy or industry driven, academic literature is generally scarce and consequently Gray Literature (GL) becomes a major source of evidence. In recent years, the adoption of Gray Literature Review (GLR) or Multivocal Literature Review (MLR) is rising steadily to provide the state-of-the-practice of a specific topic where SLR is not a viable option.
Objective:
Although some SLR guidelines recommend the use of GL and several MLR guidelines have already been proposed in SE, researchers still have conflicting views on the value of GL and commonly accepted GLR or MLR studies are generally lacking in terms of publication. This experience report aims to shed some light on GLR through a case study that uses SLR and MLR guidelines to conduct a GLR on an emerging topic in SE to specifically answer the questions related to the reasons of using GL, the processes of conducting GL, and the impacts of GL on review results.
Method:
We retrospect the review process of conducting a GLR on the topic of DevSecOps with reference to Kitchenham’s SLR and Garousi’s MLR guidelines. We specifically reflect on the processes we had to adapt in order to tackle the challenges we faced. We also compare and contrast our GLR with existing MLRs or GLRs in SE to contextualize our reflections.
Results:
We distill ten challenges in nine activities of a GLR process. We provide reasons for these challenges and further suggest ways to tackle them during a GLR process. We also discuss the decision process of selecting a suitable review methodology among SLR, MLR and GLR and elaborate the impacts of GL on our review results.
Conclusion:
Although our experience on GLR is mainly derived from a specific case study on DevSecOps, we conjecture that it is relevant and would be beneficial to other GLR or MLR studies. We also expect our experience would contribute to future GLR or MLR guidelines, in a way similar to how SLR guidelines learned from the SLR experience report a dozen years ago. In addition, other researchers may find our decision making process useful before they conduct their own reviews.}
}
@article{GAROUSI2022106697,
title = {Introduction to the Special Issue on: Grey Literature and Multivocal Literature Reviews (MLRs) in software engineering},
journal = {Information and Software Technology},
volume = {141},
pages = {106697},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106697},
url = {https://www.sciencedirect.com/science/article/pii/S095058492100152X},
author = {Vahid Garousi and Austen Rainer and Michael Felderer and Mika V. Mäntylä},
keywords = {Grey literature, Multivocal literature review, Evidence-based software engineering, Epistemology},
abstract = {In parallel to academic (peer-reviewed) literature (e.g., journal and conference papers), an enormous extent of grey literature (GL) has accumulated since the inception of software engineering (SE). GL is often defined as “literature that is not formally published in sources such as books or journal articles”, e.g., in the form of trade magazines, online blog-posts, technical reports, and online videos such as tutorial and presentation videos. GL is typically produced by SE practitioners. We have observed that researchers are increasingly using and benefitting from the knowledge available within GL. Related to the notion of GL is the notion of Multivocal Literature Reviews (MLRs) in SE, i.e., a MLR is a form of a Systematic Literature Review (SLR) which includes knowledge and/or evidence from the GL in addition to the peer-reviewed literature. MLRs are useful for both researchers and practitioners because they provide summaries of both the state-of-the-art and -practice in a given area. MLRs are popular in other fields and have started to appear in SE community. It is timely then for a Special Issue (SI) focusing on GL and MLRs in SE. From the pool of 13 submitted papers, and after following a rigorous peer review process, seven papers were accepted for this SI. In this introduction we provide a brief overview of GL and MLRs in SE, and then a brief summary of the seven papers published in this SI.}
}
@article{MERTZ2021110963,
title = {Tigris: A DSL and framework for monitoring software systems at runtime},
journal = {Journal of Systems and Software},
volume = {177},
pages = {110963},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.110963},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221000601},
author = {Jhonny Mertz and Ingrid Nunes},
keywords = {Monitoring, Logging, Execution trace, Sampling, Caching, Performance},
abstract = {The understanding of the behavioral aspects of a software system is an essential enabler for many software engineering activities, such as adaptation. This involves collecting runtime data from the system so that it is possible to analyze the collected data to guide actions upon the system. Consequently, software monitoring imposes practical challenges because it is often done by intercepting the system execution and recording gathered information. Such monitoring may degrade the performance and disrupt the system execution to unacceptable levels. In this paper, we introduce a two-phase monitoring approach to support the monitoring step in adaptive systems. The first phase collects lightweight coarse-grained information and identifies relevant parts of the software that should be monitored in detail based on a provided domain-specific language. This language is informed by a systematic literature review. The second phase collects relevant and fine-grained information needed for deciding whether and how to adapt the managed system. Our approach is implemented as a framework, called Tigris, that can be seamlessly integrated into existing software systems to support monitoring-based activities. To validate our proposal, we instantiated Tigris to support an application-level caching approach, which adapts caching decisions of a software system at runtime to improve its performance.}
}
@article{PANDEY2021114595,
title = {Machine learning based methods for software fault prediction: A survey},
journal = {Expert Systems with Applications},
volume = {172},
pages = {114595},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114595},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421000361},
author = {Sushant Kumar Pandey and Ravi Bhushan Mishra and Anil Kumar Tripathi},
keywords = {Machine learning, Fault proneness, Statistical techniques, Fault prediction, Systematic literature review},
abstract = {Several prediction approaches are contained in the arena of software engineering such as prediction of effort, security, quality, fault, cost, and re-usability. All these prediction approaches are still in the rudimentary phase. Experiments and research are conducting to build a robust model. Software Fault Prediction (SFP) is the process to develop the model which can be utilized by software practitioners to detect faulty classes/module before the testing phase. Prediction of defective modules before the testing phase will help the software development team leader to allocate resources more optimally and it reduces the testing effort. In this article, we present a Systematic Literature Review (SLR) of various studies from 1990 to June 2019 towards applying machine learning and statistical method over software fault prediction. We have cited 208 research articles, in which we studied 154 relevant articles. We investigated the competence of machine learning in existing datasets and research projects. To the best of our knowledge, the existing SLR considered only a few parameters over SFP’s performance, and they partially examined the various threats and challenges of SFP techniques. In this article, we aggregated those parameters and analyzed them accordingly, and we also illustrate the different challenges in the SFP domain. We also compared the performance between machine learning and statistical techniques based on SFP models. Our empirical study and analysis demonstrate that the prediction ability of machine learning techniques for classifying class/module as fault/non-fault prone is better than classical statistical models. The performance of machine learning-based SFP methods over fault susceptibility is better than conventional statistical purposes. The empirical evidence of our survey reports that the machine learning techniques have the capability, which can be used to identify fault proneness, and able to form well-generalized result. We have also investigated a few challenges in fault prediction discipline, i.e., quality of data, over-fitting of models, and class imbalance problem. We have also summarized 154 articles in a tabular form for quick identification.}
}
@article{WOHLIN2022106908,
title = {Successful combination of database search and snowballing for identification of primary studies in systematic literature studies},
journal = {Information and Software Technology},
volume = {147},
pages = {106908},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106908},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000659},
author = {Claes Wohlin and Marcos Kalinowski and Katia {Romero Felizardo} and Emilia Mendes},
keywords = {Systematic literature reviews, Hybrid search, Snowballing, Scopus},
abstract = {Background:
A good search strategy is essential for a successful systematic literature study. Historically, database searches have been the norm, which was later complemented with snowball searches. Our conjecture is that we can perform even better searches if combining these two search approaches, referred to as a hybrid search strategy.
Objective:
Our main objective was to compare and evaluate a hybrid search strategy. Furthermore, we compared four alternative hybrid search strategies to assess whether we could identify more cost-efficient ways of searching for relevant primary studies.
Methods:
To compare and evaluate the hybrid search strategy, we replicated the search procedure in a systematic literature review (SLR) on industry–academia collaboration in software engineering. The SLR used a more “traditional” approach to searching for relevant articles for an SLR, while our replication was executed using a hybrid search strategy.
Results:
In our evaluation, the hybrid search strategy was superior in identifying relevant primary studies. It identified 30% more primary studies and even more studies when focusing only on peer-reviewed articles. To embrace individual viewpoints when assessing research articles and minimise the risk of missing primary studies, we introduced two new concepts, wild cards and borderline articles, when performing systematic literature studies.
Conclusions:
The hybrid search strategy is a strong contender for being used when performing systematic literature studies. Furthermore, alternative hybrid search strategies may be viable if selected wisely in relation to the start set for snowballing. Finally, the two new concepts were judged as essential to cater for different individual judgements and to minimise the risk of excluding primary studies that ought to be included.}
}
@article{CICO2021110736,
title = {Exploring the intersection between software industry and Software Engineering education - A systematic mapping of Software Engineering Trends},
journal = {Journal of Systems and Software},
volume = {172},
pages = {110736},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110736},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301667},
author = {Orges Cico and Letizia Jaccheri and Anh Nguyen-Duc and He Zhang},
keywords = {Software industry, Software Engineering Education, Software Engineering Trends, Industry education intersection, Systematic mapping study},
abstract = {Context:
Software has become ubiquitous in every corner of modern societies. During the last five decades, software engineering has also changed significantly to advance the development of various types and scales of software products. In this context, Software Engineering Education plays an important role in keeping students updated with software technologies, processes, and practices that are popular in industries.
Objective:
We investigate from literature the extent Software Engineering Education addresses major Software Engineering Trends in the academic setting.
Method:
We conducted a systematic mapping study about teaching major Software Engineering Trends in project courses. We classified 126 papers based on their investigated Software Engineering Trends, specifically Software Engineering processes and practices, teaching approaches, and the evolution of Software Engineering Trends over time.
Results:
We reveal that Agile Software Development is the major trend. The other Trends, i.e., Software Implementation, Usability and Value, Global Software Engineering, and Lean Software Startup, are relatively small in the academic setting, but continuously growing in the last five years. System of Systems is the least investigated among all Trends.
Conclusions:
The study points out the possible gaps between Software Industry and Education, which implies actionable insights for researchers, educators, and practitioners.}
}
@article{KRETSOU2021110892,
title = {Change impact analysis: A systematic mapping study},
journal = {Journal of Systems and Software},
volume = {174},
pages = {110892},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110892},
url = {https://www.sciencedirect.com/science/article/pii/S016412122030282X},
author = {Maria Kretsou and Elvira-Maria Arvanitou and Apostolos Ampatzoglou and Ignatios Deligiannis and Vassilis C. Gerogiannis},
keywords = {Change impact analysis, Change proneness, Instability, Changeability, Amount of change},
abstract = {Change Impact Analysis (CIA) is the process of exploring the tentative effects of a change in other parts of a system. CIA is considered beneficial in practice, since it reduces cost of maintenance and the risk of software development failures. In this paper, we present a systematic mapping study that covers a plethora of CIA methods (by exploring 111 papers), putting special emphasis on how the CIA phenomenon can be quantified: to be efficiently managed. The results of our study suggest that: (a) the practical benefits of CIA cover any type of maintenance request (e.g., feature additions, bug fixing) and can help in reducing relevant cost; (b) CIA quantification relies on four parameters (instability, amount of change, change proneness, and changeability), whose assessment is supported by various metrics and predictors; and (c) in this vast research field, there are still some viewpoints that remain unexplored (e.g., the negative consequences of highly change prone artifacts), whereas others are over-researched (e.g., quantification of instability based on metrics). Based on our results, we provide: (a) useful information for practitioners—i.e., the expected benefits of CIA, and a list of CIA-related metrics, emphasizing on the provision of a detailed interpretation of their relation to CIA; and (b) interesting future research directions—i.e., over- and under-researched sub-fields of CIA.}
}
@article{OBAIDI2022107018,
title = {Sentiment analysis tools in software engineering: A systematic mapping study},
journal = {Information and Software Technology},
volume = {151},
pages = {107018},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.107018},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922001422},
author = {Martin Obaidi and Lukas Nagel and Alexander Specht and Jil Klünder},
keywords = {Social software engineering, Sentiment analysis, Machine learning, Systematic mapping study},
abstract = {Context:
Software development is a collaborative task. Previous research has shown social aspects within development teams to be highly relevant for the success of software projects. A team’s mood has been proven to be particularly important. It is paramount for project managers to be aware of negative moods within their teams, as such awareness enables them to intervene. Sentiment analysis tools offer a way to determine the mood of a team based on textual communication.
Objective:
We aim to help developers or stakeholders in their choice of sentiment analysis tools for their specific purpose. Therefore, we conducted a systematic mapping study (SMS).
Methods:
We present the results of our SMS of sentiment analysis tools developed for or applied in the context of software engineering (SE). Our results summarize insights from 106 papers with respect to (1) the application domain, (2) the purpose, (3) the used data sets, (4) the approaches for developing sentiment analysis tools, (5) the usage of already existing tools, and (6) the difficulties researchers face. We analyzed in more detail which tools and approaches perform how in terms of their performance.
Results:
According to our results, sentiment analysis is frequently applied to open-source software projects, and most approaches are neural networks or support-vector machines. The best performing approach in our analysis is neural networks and the best tool is BERT. Despite the frequent use of sentiment analysis in SE, there are open issues, e.g. regarding the identification of irony or sarcasm, pointing to future research directions.
Conclusion:
We conducted an SMS to gain an overview of the current state of sentiment analysis in order to help developers or stakeholders in this matter. Our results include interesting findings e.g. on the used tools and their difficulties. We present several suggestions on how to solve these identified problems.}
}
@article{BUDGEN2022106840,
title = {Short communication: Evolution of secondary studies in software engineering},
journal = {Information and Software Technology},
volume = {145},
pages = {106840},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106840},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000179},
author = {David Budgen and Pearl Brereton},
keywords = {Systematic review, Mapping study, Qualitative study, Experience of authors},
abstract = {Context:
Other disciplines commonly employ secondary studies to address the needs of practitioners and policy-makers. Since being adopted by software engineering in 2004, many have been undertaken by researchers.
Objective:
To assess how the role of secondary studies in software engineering has evolved.
Methods:
We examined a sample of 131 secondary studies published in a set of five major software engineering journals for the years 2010, 2015 and 2020. These were categorised by their type (e.g. mapping study), their research focus (quantitative/qualitative and practice/methodological), as well as the experience of the first authors.
Results:
Secondary studies are now a well-established research tool. They are predominantly qualitative and there is extensive use of mapping studies to profile research in particular areas. A significant number are clearly produced as part of postgraduate study, although experienced researchers also conduct many secondary studies. They are sometimes also used as part of a multi-method study.
Conclusion:
Existing guidelines largely focus upon quantitative systematic reviews. Based on our findings, we suggest that more guidance is needed on how to conduct, analyse, and report qualitative secondary studies.}
}
@article{GIRAY2021111031,
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111031},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111031},
url = {https://www.sciencedirect.com/science/article/pii/S016412122100128X},
author = {Görkem Giray},
keywords = {Software engineering, Software development, Software process, Machine learning, Deep learning, Systematic literature review},
abstract = {Context:
Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems.
Objective:
The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems.
Method:
I performed a systematic literature review (SLR). I systematically selected a pool of 141 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies.
Results:
The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions.
Conclusion:
The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.}
}
@article{PEREIRA2021111044,
title = {Learning software configuration spaces: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {182},
pages = {111044},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111044},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001412},
author = {Juliana Alves Pereira and Mathieu Acher and Hugo Martin and Jean-Marc Jézéquel and Goetz Botterweck and Anthony Ventresque},
keywords = {Systematic literature review, Software product lines, Machine learning, Configurable systems},
abstract = {Most modern software systems (operating systems like Linux or Android, Web browsers like Firefox or Chrome, video encoders like ffmpeg, x264 or VLC, mobile and cloud applications, etc.) are highly configurable. Hundreds of configuration options, features, or plugins can be combined, each potentially with distinct functionality and effects on execution time, security, energy consumption, etc. Due to the combinatorial explosion and the cost of executing software, it is quickly impossible to exhaustively explore the whole configuration space. Hence, numerous works have investigated the idea of learning it from a small sample of configurations’ measurements. The pattern “sampling, measuring, learning” has emerged in the literature, with several practical interests for both software developers and end-users of configurable systems. In this systematic literature review, we report on the different application objectives (e.g., performance prediction, configuration optimization, constraint mining), use-cases, targeted software systems, and application domains. We review the various strategies employed to gather a representative and cost-effective sample. We describe automated software techniques used to measure functional and non-functional properties of configurations. We classify machine learning algorithms and how they relate to the pursued application. Finally, we also describe how researchers evaluate the quality of the learning process. The findings from this systematic review show that the potential application objective is important; there are a vast number of case studies reported in the literature related to particular domains or software systems. Yet, the huge variant space of configurable systems is still challenging and calls to further investigate the synergies between artificial intelligence and software engineering.}
}
@article{AWAN2022106896,
title = {Quantum computing challenges in the software industry. A fuzzy AHP-based approach},
journal = {Information and Software Technology},
volume = {147},
pages = {106896},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106896},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000581},
author = {Usama Awan and Lea Hannola and Anushree Tandon and Raman Kumar Goyal and Amandeep Dhir},
keywords = {Fuzzy analytic hierarchy process (F-AHP), Software process automation, Multiple-criteria decision-making (MCDM), Quantum software requirement, Quantum computing},
abstract = {Context
The current technology revolution has posed unexpected challenges for the software industry. In recent years, the field of quantum computing (QC) technologies has continued to grow in influence and maturity, and it is now poised to revolutionise software engineering. However, the evaluation and prioritisation of QC challenges in the software industry remain unexplored, relatively under-identified and fragmented.
Objective
The purpose of this study is to identify, examine and prioritise the most critical challenges in the software industry by implementing a fuzzy analytic hierarchy process (F-AHP).
Method
First, to identify the key challenges, we conducted a systematic literature review by drawing data from the four relevant digital libraries and supplementing these efforts with a forward and backward snowballing search. Second, we followed the F-AHP approach to evaluate and rank the identified challenges, or barriers.
Results
The results show that the key barriers to QC adoption are the lack of technical expertise, information accuracy and organisational interest in adopting the new process. Another critical barrier is the lack of standards of secure communication techniques for implementing QC.
Conclusion
By applying F-AHP, we identified institutional barriers as the highest and organisational barriers as the second highest global weight ranked categories among the main QC challenges facing the software industry. We observed that the highest-ranked local barriers facing the software technology industry are the lack of resources for design and initiative while the lack of organisational interest in adopting the new process is the most significant organisational barrier. Our findings, which entail implications for both academicians and practitioners, reveal the emergent nature of QC research and the increasing need for interdisciplinary research to address the identified challenges.}
}
@article{VANDINTER2021106589,
title = {Automation of systematic literature reviews: A systematic literature review},
journal = {Information and Software Technology},
volume = {136},
pages = {106589},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106589},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921000690},
author = {Raymon {van Dinter} and Bedir Tekinerdogan and Cagatay Catal},
keywords = {Systematic literature review (SLR), Automation, Review, Text mining, Machine learning, Natural language processing},
abstract = {Context
Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking.
Objective
This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research.
Method
A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed.
Results
This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions.
Conclusion
According to our study, the leading automated step is the Selection of Primary Studies. Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process.}
}
@article{EBRAHIMI2021106466,
title = {Mobile app privacy in software engineering research: A systematic mapping study},
journal = {Information and Software Technology},
volume = {133},
pages = {106466},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106466},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920302123},
author = {Fahimeh Ebrahimi and Miroslav Tushev and Anas Mahmoud},
keywords = {Privacy, Mobile application, Systematic mapping study},
abstract = {Context: Mobile applications (apps) have become deeply personal, constantly demanding access to privacy-sensitive information in exchange for more personalized user experiences. Such privacy-invading practices have generated major multidimensional privacy concerns among app users. Objective: The research on mobile app privacy has experienced rapid growth over the past decade. This line of research is aimed at systematically exposing the privacy practices of apps and proposing solutions to protect the privacy of mobile app users. In this paper, we conduct a systematic mapping study of this body of research. Our objectives are to a) explore trends in SE app privacy research, b) categorize existing evidence, and c) identify potential directions for future research. Method: A systematic mapping study of 59 Software Engineering (SE) primary studies on mobile app privacy. Our scope is studies published in software engineering venues between 2008 and 2018. Results: Our results show that existing literature can be divided into four main categories: privacy policy, requirements, user perspective, and leak detection. Furthermore, our survey reveals an imbalance between these categories—the majority of existing research focuses on proposing tools for detecting privacy leaks, with fewer studies targeting privacy requirements and policy and even fewer on user perspective. Conclusions: Our survey exposes several gaps in existing research and suggests areas for improvement.}
}
@article{PETERSEN2021103541,
title = {Context checklist for industrial software engineering research and practice},
journal = {Computer Standards & Interfaces},
volume = {78},
pages = {103541},
year = {2021},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2021.103541},
url = {https://www.sciencedirect.com/science/article/pii/S0920548921000362},
author = {Kai Petersen and Jan Carlson and Efi Papatheocharous and Krzysztof Wnuk},
keywords = {Context, Software engineering, Evidence-based software engineering, Empirical, Checklist},
abstract = {The relevance of context is particularly stressed in case studies, where it is said that “case study is an empirical method aimed at investigating contemporary phenomena in their context”. In this research, we classify context information and provide a context checklist for industrial software engineering. The checklist serves the purpose of (a) supporting researchers and practitioners in characterizing the context in which they are working; (b) supporting researchers with a checklist to identify relevant contextual information to elicit and report during primary and secondary studies. We utilized a systematic approach for constructing the classification of context information and provided a detailed definition for each item. We collected feedback from researchers as well as practitioners. The usefulness of the checklist was perceived more positively by researchers than practitioners, though they highlighted benefits (raising awareness of the importance of context and usefulness for management). The understandability was perceived positively by both practitioners and researchers. The checklist may serve as a “meta-model”, forming the basis for specific adaptations for different research areas, and as input for researchers deciding which context information to extract in systematic reviews. The checklist may also help researchers in reporting context in research papers.}
}
@article{RANI2022111515,
title = {A decade of code comment quality assessment: A systematic literature review},
journal = {Journal of Systems and Software},
pages = {111515},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111515},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222001911},
author = {Pooja Rani and Arianna Blasi and Nataliia Stulova and Sebastiano Panichella and Alessandra Gorla and Oscar Nierstrasz},
keywords = {Code comments, Documentation quality, Systematic literature review},
abstract = {Code comments are important artifacts in software systems and play a paramount role in many software engineering (SE) tasks related to maintenance and program comprehension. However, while it is widely accepted that high quality matters in code comments just as it matters in source code, assessing comment quality in practice is still an open problem. First and foremost, there is no unique definition of quality when it comes to evaluating code comments. The few existing studies on this topic rather focus on specific attributes of quality that can be easily quantified and measured. Existing techniques and corresponding tools may also focus on comments bound to a specific programming language, and may only deal with comments with specific scopes and clear goals (e.g., Javadoc comments at the method level, or in-body comments describing TODOs to be addressed). In this paper, we present a Systematic Literature Review (SLR) of the last decade of research in SE to answer the following research questions: (i) What types of comments do researchers focus on when assessing comment quality? (ii) What quality attributes (QAs) do they consider? (iii) Which tools and techniques do they use to assess comment quality?, and (iv) How do they evaluate their studies on comment quality assessment in general? Our evaluation, based on the analysis of 2353 papers and the actual review of 47 relevant ones, shows that (i) most studies and techniques focus on comments in Java code, thus may not be generalizable to other languages, and (ii) the analyzed studies focus on four main QAs of a total of 21 QAs identified in the literature, with a clear predominance of checking consistency between comments and the code. We observe that researchers rely on manual assessment and specific heuristics rather than the automated assessment of the comment quality attributes, with evaluations often involving surveys of students and the authors of the original studies but rarely professional developers.}
}
@article{ALSARAYREH2021768,
title = {Software engineering principles: A systematic mapping study and a quantitative literature review},
journal = {Engineering Science and Technology, an International Journal},
volume = {24},
number = {3},
pages = {768-781},
year = {2021},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2020.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S221509862034252X},
author = {Khalid T. Al-Sarayreh and Kenza Meridji and Alain Abran},
keywords = {Software engineering, Software engineering principles, Principles development process, Systematic mapping study – SMS},
abstract = {Software engineering, a fairly recent engineering discipline, is still evolving without a wide consensus on a body of fundamental principles as in traditional engineering fields with their own long-established principles originating from physics, chemistry and mathematics. This paper reports on a systematic mapping study (SMS) that identified 30 papers and books from 1969 to January 2020, each proposing their own sets of software engineering principles (SEP). Within these studies a total of 592 SEP were proposed, these studies were reviewed and classified on the basis of four mapping questions examining publication trends, use of explicit criteria for the proposed SEP, whether authors clearly described a methodology to come up with the proposed SEP, and the applicability of SEP throughout the development process. The key finding in this study are: a) the majority of the studies were published over two decades from 1989 to 2009, and then the publication rate slowed in the following decade; b) the largest number of SEP, by far, was proposed by Davis; c) only six studies used explicit criteria to identify their proposed SEP, and the other 24 studies identified their principles based on their own analysis without traceability to a methodology or selection criteria; d) most authors did not identify which principles to use in specific contexts of the software engineering domain; e) only two studies used some of the proposed SEP throughout the software development process.}
}
@article{LI2021106449,
title = {Understanding and addressing quality attributes of microservices architecture: A Systematic literature review},
journal = {Information and Software Technology},
volume = {131},
pages = {106449},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106449},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920301993},
author = {Shanshan Li and He Zhang and Zijia Jia and Chenxing Zhong and Cheng Zhang and Zhihao Shan and Jinfeng Shen and Muhammad Ali Babar},
keywords = {Microservices, Monolith, Quality attributes, Systematic literature review},
abstract = {Context: As a rapidly adopted architectural style in software engineering, Microservices Architecture (MSA) advocates implementing small-scale and independently distributed services, rather than binding all functions into one monolith. Although many initiatives have contributed to the quality improvement of microservices-based systems, there is still a lack of a systematic understanding of the Quality Attributes (QAs) associated with MSA. Objective: This study aims to investigate the evidence-based state-of-the-art of QAs of microservices-based systems. Method: We carried out a Systematic Literature Review (SLR) to identify and synthesize the relevant studies that report evidence related to QAs of MSA. Results: Based on the data extracted from the 72 selected primary studies, we portray an overview of the six identified QAs most concerned in MSA, scalability, performance, availability, monitorability, security, and testability. We identify 19 tactics that architecturally address the critical QAs in MSA, including two tactics for scalability, four for performance, four for availability, four for monitorability, three for security, and two for testability. Conclusion: This SLR concludes that for MSA-based systems: 1) Although scalability is the commonly acknowledged benefit of MSA, it is still an indispensable concern among the identified QAs, especially when trading-off with other QAs, e.g., performance. Apart from the six identified QAs in this study, other QAs for MSA like maintainability need more attention for effective improvement and evaluation in the future. 3) Practitioners need to carefully make the decision of migrating to MSA based on the return on investment, since this architectural style additionally cause some pains in practice.}
}
@article{HERBOLD2021110802,
title = {A systematic mapping study of developer social network research},
journal = {Journal of Systems and Software},
volume = {171},
pages = {110802},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110802},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302077},
author = {Steffen Herbold and Aynur Amirfallah and Fabian Trautsch and Jens Grabowski},
keywords = {Developer social networks, Mapping study, Literature survey},
abstract = {Developer social networks (DSNs) are a tool for the analysis of community structures and collaborations between developers in software projects and software ecosystems. Within this paper, we present the results of a systematic mapping study on the use of DSNs in software engineering research. We identified 255 primary studies on DSNs. We mapped the primary studies to research directions, collected information about the data sources and the size of the studies, and conducted a bibliometric assessment. We found that nearly half of the research investigates the structure of developer communities. Other frequent topics are prediction systems build using DSNs, collaboration behavior between developers, and the roles of developers. Moreover, we determined that many publications use a small sample size regarding the number of projects, which could be problematic for the external validity of the research. Our study uncovered several open issues in the state of the art, e.g., studying inter-company collaborations, using multiple information sources for DSN research, as well as general lack of reporting guidelines or replication studies.}
}
@article{PORTO2021110870,
title = {Initiatives and challenges of using gamification in software engineering: A Systematic Mapping},
journal = {Journal of Systems and Software},
volume = {173},
pages = {110870},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110870},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302600},
author = {Daniel de Paula Porto and Gabriela Martins de Jesus and Fabiano Cutigi Ferrari and Sandra Camargo Pinto Ferraz Fabbri},
keywords = {Gamification, Software engineering, Systematic literature mapping},
abstract = {Context:
Gamification is an emerging subject that has been applied in different areas, bringing contributions to different types of activities.
Objective:
This paper aims to characterize how gamification has been adopted in non-educational contexts of software engineering (SE) activities.
Methods:
We performed a Systematic Mapping of the literature obtained from relevant databases of the area. The searches retrieved 2640 studies (published up to January 2020), of which 548 were duplicates, 82 were selected after applying the inclusion and exclusion criteria, and 21 were included via the backward snowballing technique, thus reaching a total of 103 studies to be analyzed.
Results:
Gamification provided benefits to activities like requirements specification, development, testing, project management, and support process. There is evidence of gamified support to some CMMI 2.0 Practice Areas. The most commonly used gamification elements are points and leaderboards. The main benefit achieved is the increased engagement and motivation to perform tasks.
Conclusion:
The number of publications and new research initiatives have increased over the years and, from the original authors’ reports, many positive results were achieved in SE activities. Despite this, gamification can still be explored for many SE tasks; for the addressed ones, empirical evidence is very limited.}
}
@article{CANDELAURIBE2022100935,
title = {SMS-Builder: An adaptive software tool for building systematic mapping studies},
journal = {SoftwareX},
volume = {17},
pages = {100935},
year = {2022},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2021.100935},
url = {https://www.sciencedirect.com/science/article/pii/S2352711021001710},
author = {Christian A. Candela-Uribe and Luis E. Sepúlveda-Rodríguez and Julio C. Chavarro-Porras and John A. Sanabria-Ordoñez and José Luis Garrido and Carlos Rodríguez-Domínguez and Gabriel Guerrero-Contreras},
keywords = {Systematic literature review, Systematic mapping study, Empirical software engineering},
abstract = {A Systematic Mapping Study is an instrument frequently used to carry out a search process, identification, and classification of studies in different fields. Researchers in front of this type of process have a challenge while managing the data about these studies. This paper presents a software tool that has been created to help those who need to build a systematic mapping study. In addition, this work follows the evidence-based software engineering approach and extends it through a software tool by including different ways of adapting this process.}
}
@article{PAIVA2021110819,
title = {Accessibility and Software Engineering Processes: A Systematic Literature Review},
journal = {Journal of Systems and Software},
volume = {171},
pages = {110819},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110819},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220302168},
author = {Débora Maria Barroso Paiva and André Pimenta Freire and Renata Pontin {de Mattos Fortes}},
keywords = {Accessibility, Software Engineering, Systematic Literature Review, Design for disabilities, Methods for accessibility},
abstract = {Guidelines, techniques, and methods have been presented in the literature in recent years to contribute to the development of accessible software and to promote digital inclusion. Considering that software product quality depends on the quality of the development process, researchers have investigated how to include accessibility during the software development process in order to obtain accessible software. Two Systematic Literature Reviews (SLR) have been conducted in the past to identify such research initiatives. This paper presents a new SLR, considering the period from 2011 to 2019. The review of 94 primary studies showed the distribution of publications on different phases of the software life cycle, mainly the design and testing phases. The study also identified, for the first time, papers about accessibility and software process establishment. This result reinforces that, in fact, accessibility is not characterized as a property of the final software only. Instead, it evolves over the software life cycle. Besides, this study aims to provide designers and developers with an updated view of methods, tools, and other assets that contribute to process enrichment, valuing accessibility, as well as shows the gaps and challenges which deserve to be investigated.}
}
@article{RIBEIRO2022111137,
title = {Moderator factors of software security and performance verification},
journal = {Journal of Systems and Software},
volume = {184},
pages = {111137},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111137},
url = {https://www.sciencedirect.com/science/article/pii/S016412122100234X},
author = {Victor Vidigal Ribeiro and Daniela Soares Cruzes and Guilherme Horta Travassos},
keywords = {Security, Performance, Software verification, Software testing, Evidence-based software engineering},
abstract = {Context:
Security and performance are critical software non-functional requirements. Therefore, verification activities should be included in the development process to identify related defects, avoiding failures after deployment. However, there is a lack of understanding on factors moderating the security and performance verification, which jeopardizes organizations to improve their verification activities to assure the releasing of software fulfilling these requirements.
Objective:
To identify moderator factors influencing security and performance verification and actions to promote them.
Methods:
Case study to identify security and performance moderators factors. Rapid Literature Reviews with Snowballing to strengthen moderator factors confidence. Practitioners Survey to classify the moderator factors relevance.
Results:
Identification of eight security and performance moderator factors regarding organizational awareness, cross-functional team, suitable requirements, support tools, verification environment, verification methodology, verification planning, and reuse practices. Rapid Reviews confirmed the moderator factors and revealed actions to promote each. A survey with 37 practitioners allowed us to classify the moderator factors and their actions regarding their relevancy.
Conclusions:
The moderator factors can be considered key points to software development organizations implement/improve security and performance verification activities in regular software systems. Further investigation is necessary to support the understanding of these moderator factors when building modern software systems.}
}
@article{SHAMSUJJOHA2021106693,
title = {Developing Mobile Applications Via Model Driven Development: A Systematic Literature Review},
journal = {Information and Software Technology},
volume = {140},
pages = {106693},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106693},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921001488},
author = {Md. Shamsujjoha and John Grundy and Li Li and Hourieh Khalajzadeh and Qinghua Lu},
keywords = {Systematic Literature Review, Model Driven Development, Mobile App, Tools and Techniques},
abstract = {Context:
Mobile applications (known as “apps”) usage continues to rapidly increase, with many new apps being developed and deployed. However, developing a mobile app is challenging due to its dependencies on devices, technologies, platforms, and deadlines to reach the market. One potential approach is to use Model Driven Development (MDD) techniques that simplify the app development process, reduce complexity, increase abstraction level, help achieve scalable solutions and maximize cost-effectiveness and productivity.
Objective:
This paper systematically investigates what MDD techniques and methodologies have been used to date to support mobile app development and how these techniques have been employed, to identify key benefits, limitations, gaps and future research potential.
Method:
A Systematic Literature Review approach was used for this study based on a formal protocol. The rigorous search protocol identified a total of 1,042 peer-reviewed academic research papers from four major software engineering databases. These papers were subsequently filtered, and 55 high quality relevant studies were selected for analysis, synthesis, and reporting.
Results:
We identified the popularity of different applied MDD approaches, supporting tools, artifacts, and evaluation techniques. Our analysis found that architecture, domain model, and code generation are the most crucial purposes in MDD-based app development. Three qualities – productivity, scalability and reliability – can benefit from these modeling strategies. We then summarize the key collective strengths, limitations, gaps from the studies and made several future recommendations.
Conclusion:
There has been a steady interest in MDD approaches applied to mobile app development over the years. This paper guides future researchers, developers, and stakeholders to improve app development techniques, ultimately that will help end-users in having more effective apps, especially when some recommendations are addressed, e.g., taking into account more human-centric aspects in app development.}
}
@article{LEWOWSKI2022106783,
title = {How far are we from reproducible research on code smell detection? A systematic literature review},
journal = {Information and Software Technology},
volume = {144},
pages = {106783},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106783},
url = {https://www.sciencedirect.com/science/article/pii/S095058492100224X},
author = {Tomasz Lewowski and Lech Madeyski},
keywords = {Software engineering, Code smells, Reproducibility, Reproducible research},
abstract = {Context:
Code smells are symptoms of wrong design decisions or coding shortcuts that may increase defect rate and decrease maintainability. Research on code smells is accelerating, focusing on code smell detection and using code smells as defect predictors. Recent research shows that even between software developers, agreement on what constitutes a code smell is low, but several publications claim the high performance of detection algorithms—which seems counterintuitive, considering that algorithms should be taught on data labeled by developers.
Objective:
This paper aims to investigate the possible reasons for the inconsistencies between studies in the performance of applied machine learning algorithms compared to developers. It focuses on the reproducibility of existing studies.
Methods:
A systematic literature review was performed among conference and journal articles published between 1999 and 2020 to assess the state of reproducibility of the research performed in those papers. A quasi-gold standard procedure was used to validate the search. Modeling process descriptions, reproduction scripts, data sets, and techniques used for their creation were analyzed.
Results:
We obtained data from 46 publications. 22 of them contained a detailed description of the modeling process, 17 included any reproduction data (data set, results, or scripts) and 15 used existing data sets. In most of the publications, analyzed projects were hand-picked by the researchers.
Conclusion:
Most studies do not include any form of an online reproduction package, although this has started to change recently—8% of analyzed studies published before 2018 included a full reproduction package, compared to 22% in years 2018–2019. Ones that do include a package usually use a research group website or even a personal one. Dedicated archives are still rarely used for data packages. We recommend that researchers include complete reproduction packages for their studies and use well-established research data archives instead of their own websites.}
}
@article{GONCALES2021106563,
title = {Measuring the cognitive load of software developers: An extended Systematic Mapping Study},
journal = {Information and Software Technology},
volume = {136},
pages = {106563},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106563},
url = {https://www.sciencedirect.com/science/article/pii/S095058492100046X},
author = {Lucian José Gonçales and Kleinner Farias and Bruno C. {da Silva}},
keywords = {Cognitive load, Machine learning, Software engineering, Systematic Mapping Study},
abstract = {Context:
Cognitive load in software engineering refers to the mental effort users spend while reading software artifacts. The cognitive load can vary according to tasks and across developers. Researchers have measured developers’ cognitive load for different purposes, such as understanding its impact on productivity and software quality. Thus, researchers and practitioners can use cognitive load measures for solving many aspects of software engineering problems.
Problem:
However, a lack of a classification of dimensions on cognitive load measures in software engineering makes it difficult for researchers and practitioners to obtain research trends to advance scientific knowledge or apply it in software projects.
Objective:
This article aims to classify different aspects of cognitive load measures in software engineering and identify challenges for further research.
Method:
We conducted a Systematic Mapping Study (SMS), which started with 4,175 articles gathered from 11 search engines and then narrowed down to 63 primary studies.
Results:
Our main findings are: (1) 43% (27/63) of the primary studies focused on applying a combination of sensors; (2) 81% (51/63) of the selected works were validation studies; (3) 83% (52/63) of the primary studies analyzed cognitive load while developers performed programming tasks. Moreover, we created a classification scheme based on the answers to our research questions.
Conclusion:
despite the production of a significant amount of studies on cognitive load in software engineering, there are still many challenges to be solved in this particular field for effectively measuring the cognitive load in software engineering. Therefore, this work provided directions for future studies on cognitive load measurement in software engineering.}
}
@article{DIXIT2022100314,
title = {Towards user-centered and legally relevant smart-contract development: A systematic literature review},
journal = {Journal of Industrial Information Integration},
volume = {26},
pages = {100314},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100314},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21001072},
author = {Abhishek Dixit and Vipin Deval and Vimal Dwivedi and Alex Norta and Dirk Draheim},
keywords = {Blockchain, Smart contract, Ricardian contract, Business collaboration, Legal relevance},
abstract = {Smart contracts (SC) run on blockchain technology (BCT) to implement agreements between several parties. As BCT grows, organizations aim to automate their processes and engage in business collaborations using SCs. The translation of contract semantics into SC language semantics is difficult due to ambiguous contractual interpretation by the several parties and the developers. Also, an SC language itself misses the language constructs needed for semantically expressing collaboration terms. This leads to SC coding errors that result in contractual conflicts over transactions during the performance of SCs and thus, novel SC solutions incur high development and maintenance costs. Various model-based and no/low code development approaches address this issue by enabling higher abstractions in SC development. Still, the question remains unanswered how contractual parties, i.e., end-users with non-IT skills, manage to develop legally relevant SCs with ease. This study aims to (1) identify and categorize the state of the art of SC automation models, in terms of their technical features, and their legal significance, and to (2) identify new research opportunities. The review has been conducted as a systematic literature review (SLR) that follows the guidelines proposed by Kitchenham for performing SLRs in software-engineering. As a result of the implementation of the review protocol, 1367 papers are collected, and 33 of them are selected for extraction and analysis. The contributions of this article are threefold: (1) 10 different SC automation models/frameworks are identified and classified according to their technical and implementation features; (2) 11 different legal contract parameters are identified and categorized into 4 legal criteria classes; (3) a comparative analysis of SC-automation models in the context of their legal significance is conducted that identifies the degrees to which the SC-automation models are considered legally relevant. As a conclusion, we produce a comprehensive and replicable overview of the state of the art of SC automation models and a systematic measure of their legal significance to benefit practitioners in the field.}
}
@article{WONG2021111029,
title = {A bibliometric assessment of software engineering themes, scholars and institutions (2013–2020)},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111029},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111029},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001266},
author = {W. Eric Wong and Nikolaos Mittas and Elvira Maria Arvanitou and Yihao Li},
keywords = {Bibliometrics, Top-scholars, Top-institutions, Software engineering research areas},
abstract = {This paper is the updated version (2013–2020) of the series of papers on emerging themes, top scholars and institutes on software engineering (SE), published by the Journal of Systems and Software for almost 25 years. The paper reports the findings of a bibliometric study by applying the systematic mapping technique on top-quality software engineering venues (handling a dataset of 11.668 studies). The design of the study remains the same for the complete decade, so that the results are consistent and comparable: As the ranking metric for institutions, we used the count of papers in which authors affiliated with the corresponding institute have been identified in the obtained dataset. Regarding scholars we computed the corresponding rankings based on the number of published papers and the average number of citations. In this version, the analysis of emerging trends and themes has been promoted compared to the previous years to provide more insights on what a newcomer in the software engineering domain should look at, as well as to recap the state-of-research in terms of themes to more experienced SE researchers.}
}
@article{ZAINA2022111213,
title = {Preventing accessibility barriers: Guidelines for using user interface design patterns in mobile applications},
journal = {Journal of Systems and Software},
volume = {186},
pages = {111213},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111213},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221002831},
author = {Luciana A.M. Zaina and Renata P.M. Fortes and Vitor Casadei and Leornardo Seiji Nozaki and Débora Maria Barroso Paiva},
keywords = {Accessibility, Mobile application, User interface design pattern, Software engineering, Gray literature review},
abstract = {Mobile applications play an important role in many aspects of life. It is essential to be aware of the software development approaches that can support the design of accessible applications. Their main goal is to ensure that the interactive applications are available to everyone, including people with disabilities, reduced skills, or momentarily induced impairments. This paper aims to identify the accessibility barriers that occur when using design patterns for building user interfaces of mobile apps and propose guidelines to prevent the problems most often encountered. We start by conducting a gray literature review in professional forums and blogs to reveal the difficulties developers face when using mobile user interface design patterns. We thus compiled a catalog which contains the descriptions of 9 user interface design patterns, the accessibility barriers linked to the use of each pattern and the guidelines that can be followed to prevent the problem of these barriers. We carried out an evaluation of the use of the catalog with 60 participants. Our results show that in most cases, the guidelines were correctly applied for the prototyping of mobile user interfaces. The findings also revealed the usefulness and ease-of-use of the guidelines from the perspective of the participants.}
}
@article{GONZALEZMOYANO2022107028,
title = {Uses of business process modeling in agile software development projects},
journal = {Information and Software Technology},
volume = {152},
pages = {107028},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.107028},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922001483},
author = {Cielo {González Moyano} and Luise Pufahl and Ingo Weber and Jan Mendling},
keywords = {Process models, Agile methodologies, Multi-method, Literature review, Thematic synthesis, Focus group},
abstract = {Context:
Agile methodologies and frameworks are widely used in software development projects because of their support for continuous change and delivery. Agile software development advocates de-prioritizing aspects such as processes and documentation. In traditional software engineering methodologies, however, business process models have been extensively used to support these aspects. Up until now, it is unclear to what extent recommendations to focus on code imply that conceptual modeling should be discontinued.
Objective:
The objective of this study is to investigate this hypothesis. More specifically, we develop a theoretical argument of how business process models are and can be used to support agile software development projects.
Method:
To this end, we use a multi-method study design. First, we conduct a systematic literature review, in which we identify studies on the usage of business process models in agile software development. Second, we apply procedures from thematic synthesis to analyze the connection between these uses and the phases of the development cycle. Third, we use a focus group design with practitioners to systematically reflect upon how these uses can help regarding four categories of challenges in agile software development: management, team, technology, and process.
Results:
From 37 relevant studies, we distill 15 different uses. The results highlight the benefits of process modeling as an instrument to support agile software development projects from different angles and in all project phases. Process modeling appears to be particularly relevant for the first phases of the development cycle, and for management and process issues in agile projects.
Conclusion:
We conclude that business process models indeed provide benefits for agile software development projects. Our findings have practical implications and emphasize the need for future research on modeling and agile development.}
}
@article{WANG2021111009,
title = {Can we benchmark Code Review studies? A systematic mapping study of methodology, dataset, and metric},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111009},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111009},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001060},
author = {Dong Wang and Yuki Ueda and Raula Gaikovina Kula and Takashi Ishio and Kenichi Matsumoto},
keywords = {Code Review, Mining Software Repositories, Mapping study},
abstract = {Context:
Code Review (CR) is the cornerstone for software quality assurance and a crucial practice for software development. As CR research matures, it can be difficult to keep track of the best practices and state-of-the-art in methodology, dataset, and metric.
Objective:
This paper investigates the potential of benchmarking by collecting methodology, dataset, and metric of CR studies.
Methods:
A systematic mapping study was conducted. A total of 112 studies from 19,847 papers published in high-impact venues between the years 2011 and 2019 were selected and analyzed.
Results:
First, we find that empirical evaluation is the most common methodology (65% of papers), with solution and experience being the least common methodology. Second, we highlight 50% of papers that use the quantitative method or mixed-method have the potential for replicability. Third, we identify 457 metrics that are grouped into sixteen core metric sets, applied to nine Software Engineering topics, showing different research topics tend to use specific metric sets.
Conclusion:
We conclude that at this stage, we cannot benchmark CR studies. Nevertheless, a common benchmark will facilitate new researchers, including experts from other fields, to innovate new techniques and build on top of already established methodologies. A full replication is available at https://naist-se.github.io/code-review/.}
}
@article{SAAD2021106688,
title = {UX work in software startups: A thematic analysis of the literature},
journal = {Information and Software Technology},
volume = {140},
pages = {106688},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106688},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921001452},
author = {Jullia Saad and Suéllen Martinelli and Leticia S. Machado and Cleidson R.B. {de Souza} and Alexandre Alvaro and Luciana Zaina},
keywords = {Software startup, User experience, Literature review, Thematic analysis, Software development},
abstract = {Context:
Startups are new and fast-growing innovative businesses. These companies also deal with uncertain market conditions and work under constant time and business pressures. Although User Experience (UX) has been widely adopted in the software industry, this has not been a reality in the context of software startups yet. Several factors might influence whether, which, and how UX is adopted by software startups.
Objective:
The objective of this paper is to investigate in the literature how software startups work with UX and to discover the relationship between software development practices and UX in startups.
Methodology:
Our methodology is composed of three main activities: (1) mapping the literature seeking publications on UX work, software engineering, and startups, which resulted in 21 relevant publications; (2) a thematic analysis based on the output of step 1 (i.e., the relevant literature); and (3) refining the themes found out in step 2 and the design of their relationships to explain the link between UX work and software startups.
Results:
The challenges, opportunities, and practices associated with UX in the context of software startups reported by the literature were organized in a set of themes. As a result, seven themes were defined so as to identify needs and opportunities related to UX work in startups. In addition, we synthesize open questions from the literature and suggest new ones to further research directions about the adoption of UX by software startups.
Conclusion:
Our findings demonstrate that software startups require an approach to UX that is more adherent to the startups’ dynamic and disruptive nature. We also suggest emerging open research questions which should be answered to promote the evolution of UX as applied to software startups.}
}
@article{AKILAL2022301315,
title = {An improved forensic-by-design framework for cloud computing with systems engineering standard compliance},
journal = {Forensic Science International: Digital Investigation},
volume = {40},
pages = {301315},
year = {2022},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2021.301315},
url = {https://www.sciencedirect.com/science/article/pii/S2666281721002407},
author = {Abdellah Akilal and M-Tahar Kechadi},
keywords = {Forensic-by-design, Digital forensic readiness, Forensic-ready, Cloud forensics, System and software engineering, Cloud computing systems},
abstract = {“Forensic-by-design” is an emergent and ambitious paradigm that extends the Digital Forensic Readiness (DFR) perspective. Similar to Security-by-design, this new vision advocates the integration of Forensic requirements into the system's design and development stages to get “Forensic-ready” systems. While it seems promising, we hypothesize that: (a) this new alternative is not effective for some open boundaries systems, and (b) this strategy is not fully aligned with the Systems and software Engineering (SE) standards. A six phases research methodology based on systematic literature review, mapping, and analysis was adopted. Our results confirm indeed the stated hypothesis, identify missing key factors, and point out potential omissions. A new System and software Engineering driven Forensic-by-design framework, with an emphasis on Cloud computing systems, is therefore proposed.}
}
@article{MELEGATI2021106465,
title = {Understanding Hypotheses Engineering in Software Startups through a Gray Literature Review},
journal = {Information and Software Technology},
volume = {133},
pages = {106465},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106465},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920302111},
author = {Jorge Melegati and Eduardo Guerra and Xiaofeng Wang},
keywords = {hypotheses engineering, software startups, gray literature review},
abstract = {Context
The higher availability of software usage data and the influence of the Lean Startup led to the rise of experimentation in software engineering, a new approach for development based on experiments to understand the user needs. In the models proposed to guide this approach, the first step is generally to identify, prioritize, and specify the hypotheses that will be tested through experimentation. However, although practitioners have proposed several techniques to handle hypotheses, the scientific literature is still scarce.
Objective
The goal of this study is to understand what activities, as proposed in industry, are entailed to handle hypotheses, facilitating the comparison, creation, and evaluation of relevant techniques.
Methods
We performed a gray literature review (GLR) on the practices proposed by practitioners to handle hypotheses in the context of software startups. We analyzed the identified documents using thematic synthesis.
Results
The analysis revealed that techniques proposed for software startups in practice compress five different activities: elicitation, prioritization, specification, analysis, and management. It also showed that practitioners often classify hypotheses in types and which qualities they aim for these statements.
Conclusion
Our results represent the first description for hypotheses engineering grounded in practice data. This mapping of the state-of-practice indicates how research could go forward in investigating hypotheses for experimentation in the context of software startups. For practitioners, they represent a catalog of available practices to be used in this context.}
}
@article{DALIBOR2022111361,
title = {A Cross-Domain Systematic Mapping Study on Software Engineering for Digital Twins},
journal = {Journal of Systems and Software},
volume = {193},
pages = {111361},
year = {2022},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111361},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222000917},
author = {Manuela Dalibor and Nico Jansen and Bernhard Rumpe and David Schmalzing and Louis Wachtmeister and Manuel Wimmer and Andreas Wortmann},
keywords = {Software Engineering, Digital Twins, Manufacturing, Industry 4.0},
abstract = {Digital Twins are currently investigated as the technological backbone for providing an enhanced understanding and management of existing systems as well as for designing new systems in various domains, e.g., ranging from single manufacturing components such as sensors to large-scale systems such as smart cities. Given the diverse application domains of Digital Twins, it is not surprising that the characterization of the term Digital Twin, as well as the needs for developing and operating Digital Twins are multi-faceted. Providing a better understanding what the commonalities and differences of Digital Twins in different contexts are, may allow to build reusable support for developing, running, and managing Digital Twins by providing dedicated concepts, techniques, and tool support. In this paper, we aim to uncover the nature of Digital Twins based on a systematic mapping study which is not limited to a particular application domain or technological space. We systematically retrieved a set of 1471 unique publications of which 356 were selected for further investigation. In particular, we analyzed the types of research and contributions made for Digital Twins, the expected properties Digital Twins have to fulfill, how Digital Twins are realized and operated, as well as how Digital Twins are finally evaluated. Based on this analysis, we also contribute a novel feature model for Digital Twins from a software engineering perspective as well as several observations to further guide future software engineering research in this area.}
}
@article{MIZUTANI2021100421,
title = {Software architecture for digital game mechanics: A systematic literature review},
journal = {Entertainment Computing},
volume = {38},
pages = {100421},
year = {2021},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2021.100421},
url = {https://www.sciencedirect.com/science/article/pii/S1875952121000185},
author = {Wilson K. Mizutani and Vinícius {K. Daros} and Fabio Kon},
keywords = {Systematic literature review, Digital games, Software architecture},
abstract = {Game mechanics, the rules that simulate the virtual world inside a game, take a great part in what makes a game unique. For digital games, this uniqueness reduces the opportunity for software reuse. A high-level software architecture for game mechanics, however, can still be reused where a single, specific implementation cannot. Despite that potential, existing research on game development lacks a comprehensive analysis of how game mechanics could benefit from the field of software architecture. This limits the opportunities for developers and researchers alike to benefit from findings on the subject. To help guide future research on game development, we analyzed the state-of-the-art architectures in game mechanics through a systematic literature review. This work carefully documents data from 36 studies, analyzing the reflections and compromises between design requirements, practices, and restrictions, as well as how they contribute to different types of mechanics. The main findings are that researchers favor reduced development complexity, but often tailor their solutions to specific games or genres. We conclude that a valuable avenue for future research in the field is the generalization of architectural solutions around specific types of mechanics and formalizing the use of software engineering for game mechanics.}
}